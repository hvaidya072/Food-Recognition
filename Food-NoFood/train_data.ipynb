{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import applications\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Dropout, Flatten, Dense, Conv2D, \n",
    "                          Activation, MaxPooling2D)\n",
    "\n",
    "# from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "import os, glob\n",
    "# from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150,150\n",
    "\n",
    "train_data_dir = r'C:\\Project\\Food NoFood\\Food-No Food\\train _images'\n",
    "validation_data_dir = r'C:\\Project\\Food NoFood\\Food-No Food\\valid_images'\n",
    "epochs = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu')) #tanh\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu')) #tanh\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(96))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1)) # binary\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24000 images belonging to 2 classes.\n",
      "Found 6000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1. / 255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 209s 4s/step - loss: 0.5296 - acc: 0.8270\n",
      "188/188 [==============================] - 1391s 7s/step - loss: 0.5951 - acc: 0.6952 - val_loss: 0.5296 - val_acc: 0.8270\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 169s 4s/step - loss: 0.4725 - acc: 0.8413\n",
      "188/188 [==============================] - 1277s 7s/step - loss: 0.5001 - acc: 0.8232 - val_loss: 0.4725 - val_acc: 0.8413\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 182s 4s/step - loss: 0.4483 - acc: 0.8518\n",
      "188/188 [==============================] - 1085s 6s/step - loss: 0.4680 - acc: 0.8350 - val_loss: 0.4483 - val_acc: 0.8518\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 179s 4s/step - loss: 0.4156 - acc: 0.8588\n",
      "188/188 [==============================] - 1224s 7s/step - loss: 0.4425 - acc: 0.8438 - val_loss: 0.4156 - val_acc: 0.8588\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 89s 2s/step - loss: 0.3916 - acc: 0.8737\n",
      "188/188 [==============================] - 1130s 6s/step - loss: 0.4170 - acc: 0.8505 - val_loss: 0.3916 - val_acc: 0.8737\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 159s 3s/step - loss: 0.3623 - acc: 0.8750\n",
      "188/188 [==============================] - 1046s 6s/step - loss: 0.3867 - acc: 0.8646 - val_loss: 0.3623 - val_acc: 0.8750\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 172s 4s/step - loss: 0.3449 - acc: 0.8888\n",
      "188/188 [==============================] - 1139s 6s/step - loss: 0.3703 - acc: 0.8712 - val_loss: 0.3449 - val_acc: 0.8888\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 168s 4s/step - loss: 0.3243 - acc: 0.8913\n",
      "188/188 [==============================] - 1237s 7s/step - loss: 0.3480 - acc: 0.8828 - val_loss: 0.3243 - val_acc: 0.8913\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 79s 2s/step - loss: 0.3310 - acc: 0.8882\n",
      "188/188 [==============================] - 947s 5s/step - loss: 0.3402 - acc: 0.8796 - val_loss: 0.3310 - val_acc: 0.8882\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 160s 3s/step - loss: 0.2976 - acc: 0.8980\n",
      "188/188 [==============================] - 1090s 6s/step - loss: 0.3186 - acc: 0.8898 - val_loss: 0.2976 - val_acc: 0.8980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1680a869438>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 30000//16,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 6000//16\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weightsights('food-no_food.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
